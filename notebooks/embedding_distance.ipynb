{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/4db4899737a38b2d618bbd74350915aa10293cb2/pytorch_model.bin`\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/4db4899737a38b2d618bbd74350915aa10293cb2/pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.3.1+cu121. Bad things might happen unless you revert torch to 1.x.\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.3.1+cu121. Bad things might happen unless you revert torch to 1.x.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pyannote.audio import Model\n",
    "import itertools\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from pyannote.audio import Inference\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "token = os.environ.get(\"HUGGINGFACE_ACCESS_TOKEN\")\n",
    "\n",
    "root = \"out\"\n",
    "\n",
    "files = [\n",
    "    os.path.join(root, dir, subdir, file)\n",
    "    for dir in os.listdir(root)\n",
    "    if \".DS_Store\" not in dir\n",
    "    for subdir in os.listdir(os.path.join(root, dir))\n",
    "    if \".DS_Store\" not in subdir\n",
    "    for file in os.listdir(os.path.join(root, dir, subdir))\n",
    "    if \".DS_Store\" not in file\n",
    "]\n",
    "\n",
    "model = Model.from_pretrained(\"pyannote/embedding\", use_auth_token=token)\n",
    "\n",
    "inference = Inference(model, window=\"whole\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "combos = [(a, b) for a, b in itertools.combinations(files, 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = [\n",
    "    (\n",
    "        a,\n",
    "        b,\n",
    "        cdist(\n",
    "            np.reshape(inference(a), (1, -1)),\n",
    "            np.reshape(inference(b), (1, -1)),\n",
    "            metric=\"cosine\",\n",
    "        )[0, 0],\n",
    "    )\n",
    "    for a, b in combos[:10]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('out/roadwork/012_-_Intellectual_Languages/3693.924_3721.233_SPEAKER_00.wav',\n",
       "  'out/roadwork/012_-_Intellectual_Languages/6537.867_6564.651_SPEAKER_00.wav',\n",
       "  0.1568358169578281),\n",
       " ('out/roadwork/012_-_Intellectual_Languages/3693.924_3721.233_SPEAKER_00.wav',\n",
       "  'out/roadwork/012_-_Intellectual_Languages/971.065_999.207_SPEAKER_01.wav',\n",
       "  0.9388144093192451),\n",
       " ('out/roadwork/012_-_Intellectual_Languages/3693.924_3721.233_SPEAKER_00.wav',\n",
       "  'out/roadwork/012_-_Intellectual_Languages/4517.404_4544.009_SPEAKER_00.wav',\n",
       "  0.1794177480760235),\n",
       " ('out/roadwork/012_-_Intellectual_Languages/3693.924_3721.233_SPEAKER_00.wav',\n",
       "  'out/roadwork/012_-_Intellectual_Languages/4358.609_4385.664_SPEAKER_01.wav',\n",
       "  0.8805316629822448),\n",
       " ('out/roadwork/012_-_Intellectual_Languages/3693.924_3721.233_SPEAKER_00.wav',\n",
       "  'out/roadwork/012_-_Intellectual_Languages/4401.01_4428.89_SPEAKER_00.wav',\n",
       "  0.4361329897525943),\n",
       " ('out/roadwork/012_-_Intellectual_Languages/3693.924_3721.233_SPEAKER_00.wav',\n",
       "  'out/roadwork/012_-_Intellectual_Languages/4330.648_4358.047_SPEAKER_01.wav',\n",
       "  0.8473753742618628),\n",
       " ('out/roadwork/012_-_Intellectual_Languages/3693.924_3721.233_SPEAKER_00.wav',\n",
       "  'out/roadwork/012_-_Intellectual_Languages/4429.872_4455.181_SPEAKER_00.wav',\n",
       "  0.15617192305996064),\n",
       " ('out/roadwork/012_-_Intellectual_Languages/3693.924_3721.233_SPEAKER_00.wav',\n",
       "  'out/roadwork/012_-_Intellectual_Languages/563.997_592.284_SPEAKER_00.wav',\n",
       "  0.363444404617693),\n",
       " ('out/roadwork/012_-_Intellectual_Languages/3693.924_3721.233_SPEAKER_00.wav',\n",
       "  'out/roadwork/012_-_Intellectual_Languages/2667.808_2695.468_SPEAKER_00.wav',\n",
       "  0.17919515876550585),\n",
       " ('out/roadwork/012_-_Intellectual_Languages/3693.924_3721.233_SPEAKER_00.wav',\n",
       "  'out/roadwork/015_-_One_Foot_in_The_20th_Century/1176.868_1200.259_SPEAKER_00.wav',\n",
       "  0.8806677378183464)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
